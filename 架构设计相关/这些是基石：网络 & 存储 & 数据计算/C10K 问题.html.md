---
author: zouzq7@163.com
created: "2018-11-29 02:55:43 +0000"
exporter-version: Evernote Mac 9.6.4 (470194)
source: desktop.mac
title: C10K 问题
updated: "2018-11-29 02:55:54 +0000"
---

<div>

C10K问题的本质

</div>

<div>

C10K问题的本质上是操作系统的问题。对于Web
1.0/2.0时代的操作系统，传统的同步阻塞I/O模型处理方式都是requests per
second。当创建的进程或线程多了，数据拷贝频繁（缓存I/O、内核将数据拷贝到用户进程空间、阻塞，进程/线程上下文切换消耗大，
导致操作系统崩溃，这就是C10K问题的本质。

</div>

<div>

\

</div>

<div>

可见, 解决C10K问题的关键就是尽可能减少这些CPU资源消耗。

</div>

<div>

\

</div>

<div>

C10K问题的解决方案

</div>

<div>

从网络编程技术的角度来说，主要思路：

</div>

<div>

每个连接分配一个独立的线程/进程

</div>

<div>

同一个线程/进程同时处理多个连接

</div>

<div>

\

</div>

<div>

\

</div>

<div>

\

</div>

<div>

实现方式1：传统思路最简单的方法是循环挨个处理各个连接，每个连接对应一个
socket，当所有 socket
都有数据的时候，这种方法是可行的。但是当应用读取某个 socket 的文件数据不
ready 的时候，整个应用会阻塞在这里等待该文件句柄，即使别的文件句柄
ready，也无法往下处理。

</div>

<div>

\

</div>

<div>

实现小结：直接循环处理多个连接。

</div>

<div>

问题归纳：任一文件句柄的不成功会阻塞住整个应用。

</div>

<div>

\

</div>

<div>

●
实现方式2：select要解决上面阻塞的问题，思路很简单，如果我在读取文件句柄之前，先查下它的状态，ready
了就进行处理，不 ready 就不进行处理，这不就解决了这个问题了嘛？于是有了
select 方案。用一个 fd_set
结构体来告诉内核同时监控多个文件句柄，当其中有文件句柄的状态发生指定变化（例如某句柄由不可用变为可用）或超时，则调用返回。之后应用可以使用
FD_ISSET
来逐个查看是哪个文件句柄的状态发生了变化。这样做，小规模的连接问题不大，但当连接数很多（文件句柄个数很多）的时候，逐个检查状态就很慢了。因此，select
往往存在管理的句柄上限（FD_SETSIZE）。同时，在使用上，因为只有一个字段记录关注和发生事件，每次调用之前要重新初始化
fd_set 结构体。

</div>

<div>

1

</div>

<div>

intselect(int nfds, fd_set \*readfds, fd_set \*writefds, fd_set
\*exceptfds, struct timeval \*timeout);

</div>

<div>

实现小结：有连接请求抵达了再检查处理。

</div>

<div>

问题归纳：句柄上限+重复初始化+逐个排查所有文件句柄状态效率不高。

</div>

<div>

\

</div>

<div>

● 实现方式3：poll 主要解决 select 的前两个问题：通过一个 pollfd
数组向内核传递需要关注的事件消除文件句柄上限，同时使用不同字段分别标注关注事件和发生事件，来避免重复初始化。

</div>

<div>

\

</div>

<div>

实现小结：设计新的数据结构提供使用效率。

</div>

<div>

问题归纳：逐个排查所有文件句柄状态效率不高。

</div>

<div>

\

</div>

<div>

●
实现方式4：epoll既然逐个排查所有文件句柄状态效率不高，很自然的，如果调用返回的时候只给应用提供发生了状态变化（很可能是数据
ready）的文件句柄，进行排查的效率不就高多了么。epoll
采用了这种设计，适用于大规模的应用场景。实验表明，当文件句柄数目超过 10
之后，epoll 性能将优于 select 和 poll；当文件句柄数目达到 10K
的时候，epoll 已经超过 select 和 poll 两个数量级。

</div>

<div>

\

</div>

<div>

实现小结：只返回状态变化的文件句柄。

</div>

<div>

问题归纳：依赖特定平台（Linux）。

</div>

<div>

\

</div>

<div>

因为Linux是互联网企业中使用率最高的操作系统，Epoll就成为C10K
killer、高并发、高性能、异步非阻塞这些技术的代名词了。FreeBSD推出了kqueue，Linux推出了epoll，Windows推出了IOCP，Solaris推出了/dev/poll。这些操作系统提供的功能就是为了解决C10K问题。epoll技术的编程模型就是异步非阻塞回调，也可以叫做Reactor，事件驱动，事件轮循（EventLoop）。Nginx，libevent，node.js这些就是Epoll时代的产物。

</div>

<div>

\

</div>

<div>

● 实现方式5：由于epoll, kqueue,
IOCP每个接口都有自己的特点，程序移植非常困难，于是需要对这些接口进行封装，以让它们易于使用和移植，其中libevent库就是其中之一。跨平台，封装底层平台的调用，提供统一的
API，但底层在不同平台上自动选择合适的调用。按照libevent的官方网站，libevent库提供了以下功能：当一个文件描述符的特定事件（如可读，可写或出错）发生了，或一个定时事件发生了，libevent就会自动执行用户指定的回调函数，来处理事件。目前，libevent已支持以下接口/dev/poll,
kqueue, event ports, select, poll 和
epoll。Libevent的内部事件机制完全是基于所使用的接口的。因此libevent非常容易移植，也使它的扩展性非常容易。

</div>
